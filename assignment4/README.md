# Assignment 4: Global Illumination

## Introduction

In this assignment, you are required to implement global illumination with the path tracing algorithm.

You need to render an image and save the result. Similar to assignment 3, we still use *stb_image* for image IO and * Eigen* as the math lib. *tinyobjloader* is provided to read triangle meshes.

You can click the [link](https://classroom.github.com/a/vfJ2ouRU) to accept the homework from GitHub classroom.

In the following, we will give you the specifics about what you need to accomplish, as well as some related guidelines to assist your programming. When you have finished all your work, you will need to complete an assignment report (in report directory) to show how you completed the assignment, which needs to be written using LATEX.

## Programming Requirements

### Must

- Path tracing with Monte Carlo integration, direct + indirect lighting (40 pts)
- Ideal diffuse BRDF and area light source (20 pts)
- Acceleration structure: BVH (30 pts)

### Bonus

- The ideal specular or glossy specular BRDF (10 pts)
- The translucent BRDF with refraction, e.g. glasses and diamonds. (10 pts)
- Environment lighting (15 pts)
- Advanced BVH with higher performance. (20 pts)
- Challenging problems: (each with 30 pts)
  - Efficiently sample multiple light sources
  - Bidirectional path tracing
  - Metropolis light transport
  - Photon mapping

## Demonstration Requirements

In addition to program, you will also need to demonstrate your code to TAs.

Things you should prepare:

- Explain how you implement the path tracing algorithm with direct lighting and indirect lighting.
- Explain how you implement an ideal diffuse BRDF and an area light. In particular, you should explain how you evaluate and sample it.
- Explain how to build a BVH for a triangle mesh and how to traverse over the tree to do intersection test efficiently.
- For the optional part, explain your implementation and show it! Please show us proper example pictures to demonstrate your result.

## Submission

You are required to push following items to GitHub repository:

- Your source codes.
- All images you rendered **in full resolution**. You should at least upload two images, rendered by two json files provided in template. Image resolution should be higher than 600 by 600, and spp should be at least 128.
- A PDF-formatted report. You should use the LaTeX template we provided.

Submission deadline: **22:00, December 2, 2022**

## Grading Rules

- You will get additional scores if you choose to do bonus items. Please prepare convincing results to prove that your implementation of bonus item(s) is(are) correct. The maximum additional score is 30 points.
- NO CHEATING! You should work independently. Please note that images you submitted or showed to TAs when doing offline check should be generated by the code you pushed on GitHub. We will run your code on GitHub to verify that.
- Late submission will be subject to score deduction rules on the course website.

## Skeleton Project/Report Template

The skeleton program and report template will be provided once you accept the assignment link of GitHub classroom which we published in Piazza. If you accept the assignment through link properly, a repository which contains the skeleton project and report template will be created under your GitHub account. Please follow the template to prepare your report.

In this assignment, we provide you with a simple json parser using *nlohmann*. You can write a configuration json file and parse the file as runtime parameters to switch between different scene settings easily. The json file is read from disk and its content is parsed to a class named *Config*. You can add your own json files to create custom scene.

## Implementation Guide

### Path Tracing with Monte-Carlo Integration

This part is the most critical one for rendering realistic images. You are supposed to complete the `Integrator::render` and `Integrator::radiance` methods. To compute the radiance of each pixel in the image plane, you need to construct paths starting from the camera and compute the Monte-Carlo integration along these paths in order to solve the light transport equation. The iterative implementation of path tracing can be briefly summarized as

```
Beta = 1, L = 0
Generate a ray from the camera to a pixel on the image plane  
For i = 1 to max depth  
(0) Suppose the marching ray hits at P(i)
(1) L += Beta * Direct lighting at P(i)  
(2) Sample ONE next ray according to P(i)'s BRDF and find the corresponding Pdf
(3) Beta *= BRDF * cosÎ˜ / Pdf
(4) Spawn and march the new ray  
where L is the output radiance. 
```

You may find more knowledge about the light transport equation and how to implement an iterative-version of path tracing in this [site](https://www.pbr-book.org/3ed-2018/Light_Transport_I_Surface_Reflection/Path_Tracing).

For the direct lighting, here you only need to implement the sampling from the area light. If you choose to implement other BRDFs, you may need to sample both the light and the BRDF through multiple importance sampling.

related file: `integrator.cpp`

### Ideal Diffusion BRDF

Differing from the Phong model used in assignment 3, this assignment requires you to implement an ideal diffuse BRDF, for which you are able to sample solid angles and obtain the corresponding PDFs (probability density function). In the `IdealDiffusion::sample` method, you need to perform sampling on the local hemi-sphere in order to determine the sampled direction. The `BSDF::pdf` method is expected to compute the PDF of a sampled direction. While the `BSDF::evaluate` method, you need to return the BSDF value according to the given interaction. We recommend using the cosine-weighted hemisphere sampling method as introduced in lecture 12. The site2 will further help you figure out how to sample different types of reflection functions, like glossy specular reflection.

When sampling a new direction for incoming radiance, we need a transformation between a local hemisphere and a global one. You can use `Eigen::Quaternion::FromTwoVectors` and `Eigen::Quaternion::toRotationMatrix` to do such transformation.

related files `brdf.h`, `brdf.cpp`

### Area Light

For area light, we need to sample the light's positions, similar to sampling directions from the BRDF. The sampled position is used for direct light sampling.

The `AreaLight::emission` method is expected to return the emitted radiance at the given position along the given direction. (For SquareAreaLight, position of sample point on light does not matter since it's uniform.) Emission strength is cosine-weighted. In the `AreaLight::pdf` method, you need to compute and return the PDF of a sampled light position (or corresponding solid angle). And the `AreaLight::sample` is designed for sampling a position on the area light.

**Note: In this assignment, for SquareAreaLight, we always assume that the normal direction is pointing downward (0, -1, 0)**

related files `light.h` `light.cpp`

Now, you can try to run your program with configurations in `simple.json` to check the correctness of your implementation.

### BVH as an acceleration structure

In this assignment, you are only required to build BVH for each object. The root node of BVH is attached to class `TriangleMesh`. (Please note that such practice is inefficient if you have many objects in the scene.)

related files: `geometry.cpp`, `geometry.h`, `accel.h`, `accel.cpp`

### Expected results for must part

- setting 1: using `simple.json`. rendered in 110 sec. No BVH.
- setting 2: using `large_mesh.json`, rendered in 125 sec. box, dragon and bunny have their own BVH.

Resolution: of 600 by 600. 256 samples per pixel.
Test platform: Intel i7 10700 (8-core 16-threads)

![simple](https://faculty.sist.shanghaitech.edu.cn/faculty/liuxp/course/cs171.01/assignment/assignment4/simple.png)![large_mesh](https://faculty.sist.shanghaitech.edu.cn/faculty/liuxp/course/cs171.01/assignment/assignment4/large_mesh.png)

### Specular/Glossy/Translucent BRDF

Similar to ideal diffuse BRDF, you need to implement `evaluate()`, `pdf()` and `sample()` for each of them. To support new BRDF in json, you may need to modify `config.h`, `config_io.h` and `scene.cpp`. Check this [site](https://www.pbr-book.org/3ed-2018/Reflection_Models/Specular_Reflection_and_Transmission) to learn more. You may need to implement the multiple importance sampling to handle these BRDFs.

### Environment Lighting

You need to load an environment texture from file and use it as the light source. You can download environment texture from [here](https://polyhaven.com/a/clarens_night_02). Then you can load texture by `stb_image`.

### Advanced BVH

You can implement more advanced BVH as introduced in tutorial 7. You may need to build BVH for the whole scene, rather than within one mesh object. You can also implement a hybrid acceleration structure (e.g. Grid + BVH).

**Note: You do not need to implement the simple BVH in must part, as long as you can implement your advanced acceleration structure correctly.**

### Challenging Problems

In this assignment, we encourage you to implement some advanced algorithms. You can get 30 points for implementing any of these algorithms correctly. We have introduced bidirectional path tracing, Metropolis light transport and photon mapping in class. Here we just give a detailed description for efficient light source sampling.

If you have multiple light sources in the scene, one simple strategy is that you randomly select one light with equal probability. However, this strategy is extremely inefficient. For example, for a given intersection point, some light sources are blocked by other objects. Then it makes no sense to sample those invisible light. Also, different light sources have different contributions to the radiance, and we try to sample the light with the greatest contribution to the radiance. You need to design an algorithm to improve sampling efficiency.

ï¿½ï¿½